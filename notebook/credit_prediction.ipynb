{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3a916e5-b7ad-4e92-a118-a189b278e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import optuna\n",
    "\n",
    "from giskard import Dataset, Model, scan, testing\n",
    "import pickle\n",
    "\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "import warnings\n",
    "\n",
    "# import clickhouse_connect\n",
    "import psycopg2\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "import clickhouse_connect\n",
    "\n",
    "import mlflow \n",
    "import mlflow.catboost\n",
    "import mlflow.sklearn\n",
    "import mlflow.data\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26599f47-ec65-4763-a45c-6c8cf27ef447",
   "metadata": {},
   "source": [
    "# Env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af346c89-40de-4503-90ee-8563280f7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "SPARK_COMPAT_VERSION = os.getenv('SPARK_COMPAT_VERSION')\n",
    "SCALA_COMPAT_VERSION = os.getenv('SCALA_COMPAT_VERSION')\n",
    "CATBOOST_SPARK_VERSION = os.getenv('CATBOOST_SPARK_VERSION')\n",
    "DB_HOST = os.getenv('DB_HOST')\n",
    "POSTGRESQL_PORT = os.getenv('POSTGRESQL_PORT')\n",
    "CLICKHOUSE_PORT = os.getenv('CLICKHOUSE_PORT')\n",
    "DB_USER = os.getenv('DB_USER')\n",
    "DB_PASSWORD = os.getenv('DB_PASSWORD')\n",
    "DB_NAME = os.getenv('DB_NAME')\n",
    "\n",
    "ACCESS_KEY=os.getenv('MINIO_ROOT_USER')\n",
    "SECRET_KEY=os.getenv('MINIO_ROOT_PASSWORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590242f9-cf3b-4fb8-ba6d-2a9acf890467",
   "metadata": {},
   "source": [
    "# Set feature and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4611343e-78af-4c09-875b-a4d3ba88e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_TYPES = {\n",
    "    'age': 'numeric',\n",
    "    'sex': 'category',\n",
    "    'job': 'category',\n",
    "    'housing': 'category',\n",
    "    'credit_amount': 'numeric',\n",
    "    'duration': 'numeric'\n",
    "}\n",
    "\n",
    "TARGET_COLUMN_NAME = 'default'\n",
    "FEATURE_COLUMNS = [i for i in COLUMN_TYPES.keys()]\n",
    "FEATURE_TYPES = {i: COLUMN_TYPES[i] for i in COLUMN_TYPES if i != TARGET_COLUMN_NAME}\n",
    "\n",
    "COLUMNS_TO_SCALE = [key for key in COLUMN_TYPES.keys() if COLUMN_TYPES[key] == \"numeric\"]\n",
    "COLUMNS_TO_ENCODE = [key for key in COLUMN_TYPES.keys() if COLUMN_TYPES[key] == \"category\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df61e3a8-7dcc-4786-a4de-7b0617a3f600",
   "metadata": {},
   "source": [
    "# Connect to db (data) and get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99036d0f-8e52-48a9-9eab-e48bb79b52e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = clickhouse_connect.get_client(host = CLICKHOUSE_HOST, \n",
    "#                                        port = CLICKHOUSE_PORT, \n",
    "#                                        user = CLICKHOUSE_USER, \n",
    "#                                        password = CLICKHOUSE_PASSWORD)\n",
    "# query = fr'''\n",
    "# select {reduce(lambda a,b: a + ', ' + b, FEATURE_COLUMNS)}\n",
    "# from credit.credit\n",
    "# '''\n",
    "# X = pd.DataFrame(client.query(query).named_results())\n",
    "# X\n",
    "\n",
    "job_list = {\n",
    "    0: 'unskilled and non-resident', \n",
    "    1: 'unskilled and resident', \n",
    "    2: 'skilled', \n",
    "    3: 'highly skilled'\n",
    "}\n",
    "\n",
    "\n",
    "## Postgresql ==============================================\n",
    "conn = psycopg2.connect(dbname='credit',\n",
    "                                user=DB_USER,\n",
    "                                password=DB_PASSWORD,\n",
    "                                host='localhost',\n",
    "                                port=POSTGRESQL_PORT)\n",
    "cur = conn.cursor()\n",
    "cur.execute(f\"SELECT {reduce(lambda a,b: a + ', ' + b, FEATURE_COLUMNS)} FROM credit;\")\n",
    "X = (\n",
    "    pd\n",
    "    .DataFrame(cur.fetchall(), columns=FEATURE_COLUMNS)\n",
    "    .assign(job = lambda x: x['job'].apply(lambda x: job_list[x]))\n",
    ")\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(dbname='credit',\n",
    "                                user=DB_USER,\n",
    "                                password=DB_PASSWORD,\n",
    "                                host='localhost',\n",
    "                                port=POSTGRESQL_PORT)\n",
    "cur = conn.cursor()\n",
    "cur.execute(f'SELECT cr.\"{TARGET_COLUMN_NAME}\" FROM credit cr;')\n",
    "y = [x[0] for x in cur.fetchall()]\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "df = X.join(pd.DataFrame(y, columns = [TARGET_COLUMN_NAME]))\n",
    "#=================================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd38048b-ed2b-47d1-86f5-0cdbc3043c10",
   "metadata": {},
   "source": [
    "# MLflow connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d8450d7-e83c-45b3-9259-3c4e16df79bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URI http://localhost:5000/\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "mlflow.set_tracking_uri('http://localhost:5000/')\n",
    "print(\"URI\", mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0894caf9-1795-4e10-a5d4-d17d1da8dbc2",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed2f34df-25df-4117-856f-2a9753e202fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps = [\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps = [\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "# \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, COLUMNS_TO_SCALE),\n",
    "        (\"cat\", categorical_transformer, COLUMNS_TO_ENCODE)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3279f01f-7a24-46f0-ad37-bf59f305329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_preproccessed = preprocessor.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size = 0.25,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ef5dc8-ce11-4059-b53e-324179d183d3",
   "metadata": {},
   "source": [
    "### Optimize hyperparams (optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cea44e9-bd2a-403b-a53b-3391b3dcab6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 20:58:13,339] A new study created in memory with name: params_opt_20250513-205813\n",
      "[I 2025-05-13 20:58:40,177] Trial 0 finished with value: 0.2733333333333333 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0781534979726857, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli'}. Best is trial 0 with value: 0.2733333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run run_13.05.2025_20:58:13 at: http://localhost:5000/#/experiments/3/runs/e65530c6930145b8895826c962b5a65d\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 20:58:48,708] Trial 1 finished with value: 0.2733333333333333 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09144275187578509, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.2733333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run run_13.05.2025_20:58:40 at: http://localhost:5000/#/experiments/3/runs/87c710ab940b4f3e9080c8d7c170e61e\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 20:58:55,582] Trial 2 finished with value: 0.26 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08264827862361696, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli'}. Best is trial 2 with value: 0.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run run_13.05.2025_20:58:48 at: http://localhost:5000/#/experiments/3/runs/b46cce8d2bb14534b40961190bb82df3\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 20:59:03,312] Trial 3 finished with value: 0.18 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.06405782107884113, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli'}. Best is trial 3 with value: 0.18.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run run_13.05.2025_20:58:55 at: http://localhost:5000/#/experiments/3/runs/da15f01e058e432f994c6bc7d3771055\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/13 20:59:07 WARNING mlflow.utils.requirements_utils: Found pandas version (2.1.4+dfsg) contains a local version label (+dfsg). MLflow logged a pip requirement for this package as 'pandas==2.1.4' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/13 20:59:07 WARNING mlflow.utils.requirements_utils: Found pandas version (2.1.4+dfsg) contains a local version label (+dfsg). MLflow logged a pip requirement for this package as 'pandas==2.1.4' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/13 20:59:07 WARNING mlflow.utils.requirements_utils: Found lz4 version (4.0.2+dfsg) contains a local version label (+dfsg). MLflow logged a pip requirement for this package as 'lz4==4.0.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run params_opt_13.05.2025_20:58 at: http://localhost:5000/#/experiments/3/runs/ea02069264f8475a94a00efec43305f5\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):    \n",
    "    # CatBoostClassifier hyperparams\n",
    "    params = {\n",
    "        \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
    "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\n",
    "            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n",
    "        ),\n",
    "        \"used_ram_limit\": \"3gb\",\n",
    "    }\n",
    "    with mlflow.start_run(run_name = f'run_{datetime.now().strftime('%d.%m.%Y_%H:%M:%S')}', nested=True):\n",
    "        \n",
    "        # model\n",
    "        mlflow.log_params(params)\n",
    "        estimator = CatBoostClassifier(**params, verbose=False)\n",
    "        \n",
    "        recall = cross_val_score(estimator, X_preproccessed, y, cv=5, scoring= 'recall').mean()\n",
    "        mlflow.log_metric('Recall', recall) \n",
    "        return recall\n",
    "\n",
    "\n",
    "experiment_name = f'credit_pred_{datetime.now().strftime('01.%m.%Y')}'\n",
    "try:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "except:\n",
    "    pass\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run(run_name = f'params_opt_{datetime.now().strftime('%d.%m.%Y_%H:%M')}') as run:\n",
    "    study = optuna.create_study(direction=\"minimize\", study_name=f\"params_opt_{datetime.now().strftime('%Y%m%d-%H%M%S')}\")\n",
    "\n",
    "    # Hyperparams searching\n",
    "    study.optimize(objective, n_trials=4)\n",
    "    \n",
    "    # best result is\n",
    "    params = study.best_params\n",
    "\n",
    "    estimator = CatBoostClassifier(**params, verbose=False)  \n",
    "    catboostclassifier = Pipeline(steps = [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", estimator)\n",
    "    ])\n",
    "    # catboostclassifier = CatBoostClassifier(**params, verbose=False)\n",
    "    catboostclassifier.fit(X_train, y_train)\n",
    "    \n",
    "    pred_test = catboostclassifier.predict(X_test)\n",
    "    signature = infer_signature(X_test, pred_test)\n",
    "\n",
    "    \n",
    "    metrics = {'accuracy': accuracy_score(pred_test, y_test),\n",
    "                'precision': precision_score(pred_test, y_test),\n",
    "                'recall': recall_score(pred_test, y_test),\n",
    "                'f1': f1_score(pred_test, y_test),\n",
    "                'roc_auc': roc_auc_score(y_test, catboostclassifier.predict_proba(X_test)[:,1])\n",
    "              }\n",
    "\n",
    "    \n",
    "    input_example = X_train.iloc[[0], :]\n",
    "    mlflow.models.infer_signature(input_example, 0, params)\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    dataset = mlflow.data.from_pandas(df, name='german_credit', targets='default')\n",
    "    mlflow.log_input(dataset)\n",
    "\n",
    "    mlflow.sklearn.log_model(sk_model=catboostclassifier, \n",
    "                              artifact_path='catboostclassifier', \n",
    "                              signature=signature,\n",
    "                              input_example=input_example\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe02a42-0aeb-4bdf-993c-eb9ffb6d7539",
   "metadata": {},
   "source": [
    "## Wrap dataset with Giskard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1565001-06d6-460d-b5e2-7e114bf2e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.concat([X_test, y_test], axis = 1)\n",
    "giskard_dataset = Dataset(\n",
    "    df = raw_data,\n",
    "    target=TARGET_COLUMN_NAME,\n",
    "    name = \"German credit scoring dataset\",\n",
    "    cat_columns=COLUMNS_TO_ENCODE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7daf2c4-33de-4df9-bbdb-111d1725bc65",
   "metadata": {},
   "source": [
    "## Wrap model with Giskard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1fb196-bd6e-4385-bc32-49165cb2cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "giskard_model = Model(\n",
    "    model=catboostclassifier,\n",
    "    model_type=\"classification\",     # Either regression, classification or text_generation.\n",
    "    name=\"Chunk classification\",\n",
    "    classification_labels=catboostclassifier.classes_,  # Their order MUST be identical to the prediction_function's output order\n",
    "    feature_names=FEATURE_COLUMNS     # Default: all columns of your dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36044d8-cbe6-437e-9a9d-9d28e1f6aa3c",
   "metadata": {},
   "source": [
    "## Scan model with Giskard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c231a9-5af7-4a1a-9890-efe3e96e7d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = scan(giskard_model, giskard_dataset, verbose=False)\n",
    "results.to_html(\"giskard_scan_result.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70fd3a0-c172-4a88-919a-aa3b2656c1b1",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed2525a2-5b60-4346-9bc2-59e8564de9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(catboostclassifier, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe7b143-5840-46e3-acb4-96baea5b1f40",
   "metadata": {},
   "source": [
    "# Minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c52214d5-82e8-4c73-812a-2c373f72c87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket credit-model already exists\n",
      "model.pkl successfully uploaded as object model.pkl to bucket credit-model\n"
     ]
    }
   ],
   "source": [
    "def s3_upload_model():\n",
    "    # Create a client with the MinIO server playground, its access key\n",
    "    # and secret key.\n",
    "    client = Minio(\"localhost:9099\",\n",
    "        access_key=ACCESS_KEY,\n",
    "        secret_key=SECRET_KEY,\n",
    "        secure=False\n",
    "    )\n",
    "\n",
    "    # The file to upload, change this path if needed\n",
    "    source_file = \"model.pkl\"\n",
    "\n",
    "    # The destination bucket and filename on the MinIO server\n",
    "    bucket_name = \"credit-model\"\n",
    "    destination_file = \"model.pkl\"\n",
    "\n",
    "    # Make the bucket if it doesn't exist.\n",
    "    found = client.bucket_exists(bucket_name)\n",
    "    if not found:\n",
    "        client.make_bucket(bucket_name)\n",
    "        print(\"Created bucket\", bucket_name)\n",
    "    else:\n",
    "        print(\"Bucket\", bucket_name, \"already exists\")\n",
    "\n",
    "    # Upload the file, renaming it in the process\n",
    "    client.fput_object(\n",
    "        bucket_name, destination_file, source_file,\n",
    "    )\n",
    "    print(\n",
    "        source_file, \"successfully uploaded as object\",\n",
    "        destination_file, \"to bucket\", bucket_name,\n",
    "    )\n",
    "\n",
    "try:\n",
    "    s3_upload_model()\n",
    "except S3Error as exc:\n",
    "    print(\"error occurred.\", exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401d0473-9416-4298-b17c-4d25028a3cde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
